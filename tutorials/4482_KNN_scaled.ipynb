{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4482_KNN_scaled.ipynb","provenance":[{"file_id":"1_K19xrWbt-bOPLoeje92_1WGtkqzbNws","timestamp":1635557870328},{"file_id":"1ef5IwJiJkE7WTZN3Mf5ylLd0q5AF6KoR","timestamp":1625870849724},{"file_id":"1E_cXZQs6Zk6Hoq-4T-XdaOz-i3mi4cPE","timestamp":1624304941540}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yjBcE37Ox_fE"},"source":["In this notebook we will be covering a new modeling technique called K-Nearest Neighbors. \n","\n","A quick reminder about the model requirements that Dr. Sheng talks about in her videos are that the data must be standardized to have each column be on the same scale. Having columns on different scales will cause issues with distance calculations.\n","\n","We will demonstrate this before diving deeper.\n","\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"]},{"cell_type":"markdown","metadata":{"id":"qjKEFgC7Ycm_"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"IbDv78ea7uk-"},"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, confusion_matrix,\\\n","recall_score, precision_score, f1_score, accuracy_score, make_scorer,\\\n","precision_recall_fscore_support, mean_absolute_error, mean_squared_error\n","\n","from sklearn.model_selection import train_test_split, cross_validate\n","\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","from google.colab import drive\n","import seaborn as sns\n","\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.dummy import DummyClassifier\n","\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FqyRu9C4YfJy"},"source":["## Data"]},{"cell_type":"code","metadata":{"id":"ecg-Mm7UeaG8"},"source":["! ls /content/drive/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZL9otp_39m7r"},"source":["titanic_cleaned = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/6482_to_4482/titanic_cleaned.csv').drop('Cabin',axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifk5nluWDuf7"},"source":["titanic_cleaned.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SuEa_lDSW1-_"},"source":["X = pd.get_dummies(titanic_cleaned.drop('Survived', axis=1))\n","y = titanic_cleaned.Survived\n","print(X.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zHROsst8Crci"},"source":["# Model assumption testing preparation"]},{"cell_type":"markdown","metadata":{"id":"vjGHnIxU9xGG"},"source":["##demonstrate a random number generator"]},{"cell_type":"code","metadata":{"id":"P6AZd4i_oP7d"},"source":["import random\n","random.randint(100000,9999999) # generate a really big number randomly"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l0iqNtjw920I"},"source":["## apply random numbers to a new column"]},{"cell_type":"code","metadata":{"id":"jTKbieZSfKD0"},"source":["X_random_col = X.copy()\n","X_random_col['a_random_big'] = random.sample(range(9999999, 99999999), X_random_col.shape[0]) # now generate a bunch of random numbers one new number for each row\n","X_random_col[['Age','a_random_big']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r7nkiLsIb3Y7"},"source":["# Standard Scaler\n","\n","StandardScaler allows us to convert existing unscaled data into scaled data. A quick demonstration showing this in action on our dataframe is below. Notice how our data is on different scales prior to transforming the data with StandardScaler"]},{"cell_type":"markdown","metadata":{"id":"9RMxI2UrcJUR"},"source":["Before"]},{"cell_type":"code","metadata":{"id":"XUyqm7sAb22f"},"source":["X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkfZMb7ecNIZ"},"source":["After\n","\n","notice that we have lost our column names, but the data is now much consistent. technically we don't need to scale our One-Hot encoded data as the scale was very close already, but we let StandardScaler transform it for ease of reading here. "]},{"cell_type":"code","metadata":{"id":"OMmcVnBvcMq2"},"source":["pd.DataFrame(StandardScaler().fit_transform(X))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h0EPzsXY9_A0"},"source":["## now do the same to a lot of columns "]},{"cell_type":"code","metadata":{"id":"JX441bstzM-G"},"source":["X_random_columns_scaled = X.copy()\n","X_random_columns_scaled['a_random_big'] = random.sample(range(9999999, 99999999), X_random_col.shape[0])\n","X_random_columns_scaled['b_random_big'] = random.sample(range(9999999, 99999999), X_random_col.shape[0])\n","X_random_columns_scaled['c_random_big'] = random.sample(range(9999999, 99999999), X_random_col.shape[0])\n","X_random_columns_scaled['d_random_big'] = random.sample(range(9999999, 99999999), X_random_col.shape[0])\n","X_random_columns_scaled['e_random_big'] = random.sample(range(9999999, 99999999), X_random_col.shape[0])\n","\n"," # now generate a bunch of random numbers one new number for each row\n","print('prescaled',\"\\n\")\n","display(X_random_columns_scaled[['Age','a_random_big','b_random_big','c_random_big','d_random_big','e_random_big']].head())\n","\n","#now scale\n","\n","# keep the column names since we will lose them\n","column_names = X_random_columns_scaled.columns\n","\n","X_random_columns_scaled = StandardScaler().fit_transform(X_random_columns_scaled)\n","X_random_columns_scaled = pd.DataFrame(X_random_columns_scaled,columns = column_names )\n","print(\"\\n\",'scaled')\n","X_random_columns_scaled.head()\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rexrF4gOIMI5"},"source":["# Dummy Classifier\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html\n","\n","dummy classifiers are useful because they allow us to see how a Naive classification strategy would perform. This establishes a baseline that we can try and beat with our model. It's often suprisingly hard to do better than some of these strategies. "]},{"cell_type":"code","metadata":{"id":"GGsFZziermJM"},"source":["print(\"uniform f1 cv score:\",round(cross_val_score(DummyClassifier(strategy=\"uniform\"),X_random_col, y,scoring='f1').mean(),2))\n","print(\"stratified f1 cv score:\",round(cross_val_score(DummyClassifier(strategy=\"stratified\"),X_random_col, y,scoring='f1').mean(),2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4aNU8BxADVO"},"source":["parameters = {'n_neighbors': [i for i in range(50)],\n","              'p': [i for i in range(2)]  \n","              }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d3R-FEFlI39q"},"source":["# KNN with unscaled data with random large columns\n","\n","Notice the performance here. Since we have data that is unscaled our model performs no better than the stratified dummy classifier. This is a poor performing model because our data is not prepared properly. "]},{"cell_type":"code","metadata":{"id":"MI8X5x6IqQUg"},"source":["clf = GridSearchCV(KNeighborsClassifier(), parameters,scoring='f1').fit(X_random_col, y)\n","result_df = pd.DataFrame(clf.cv_results_)\n","result_df[result_df['rank_test_score']==1]['mean_test_score']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PSOzCDTmI-Hn"},"source":["# KNN with scaled data random columns\n","\n","Notice the performance here. Now that we have scaled our data our model performance is substantially better than our unscaled and dummy classifiers. "]},{"cell_type":"code","metadata":{"id":"7GstBBcz0hXJ"},"source":["clf = GridSearchCV(KNeighborsClassifier(), parameters,scoring='f1').fit(X_random_columns_scaled, y)\n","result_df = pd.DataFrame(clf.cv_results_)\n","result_df[result_df['rank_test_score']==1]['mean_test_score']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cte0ofE2JdhG"},"source":["# KNN with scaled original data\n","\n","Notice the performance here. Eliminating the random columns increases the performance slightly. "]},{"cell_type":"code","metadata":{"id":"g5r82Gklddv4"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","scaler.fit(X)\n","\n","X_scaled = scaler.transform(X)\n","X_scaled[:2]\n","\n","# notice that StandardScaler has converted the data to a numpy array. we have lost the column names. "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkIbG2qTrK44"},"source":["clf = GridSearchCV(KNeighborsClassifier(), parameters,scoring='f1').fit(X_scaled, y)\n","result_df = pd.DataFrame(clf.cv_results_)\n","result_df[result_df['rank_test_score']==1]['mean_test_score']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9iyfH2CYgR8"},"source":["## KNN hyperparameter exploration"]},{"cell_type":"code","metadata":{"id":"8pIyKTNUZm2_"},"source":["parameters = {'n_neighbors': [i for i in range(150)],\n","              'p': [i for i in range(2)]  \n","              }\n","\n","clf = GridSearchCV(KNeighborsClassifier(), parameters,scoring='f1').fit(X_scaled, y)\n","result_df = pd.DataFrame(clf.cv_results_)\n","#result_df[result_df['rank_test_score']==1]['mean_test_score']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJdMYTMiaXS-"},"source":["Evaluating the model default of 5 nearest neighbors. Would that strategy have achieve good results for us in this modeling task?"]},{"cell_type":"code","metadata":{"id":"gmeT2cg6aE2t"},"source":["sns.lmplot('param_n_neighbors', 'mean_test_score', data=result_df , fit_reg=False)\n","plt.title(\"all models mean F1 score optimized by n_neighbors\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cO1jr9zHa2ug"},"source":["result_df[['param_n_neighbors','param_p','mean_test_score']].sort_values(by='mean_test_score',ascending=False).head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYQ2WWEfgwnH"},"source":["!cp \"/content/drive/My Drive/Colab Notebooks/4482_KNN_scaled.ipynb\" ./\n","\n","# run the second shell command, jupyter nbconvert --to html \"file name of the notebook\"\n","# create html from ipynb\n","\n","!jupyter nbconvert --to html \"4482_KNN_scaled.ipynb\""],"execution_count":null,"outputs":[]}]}