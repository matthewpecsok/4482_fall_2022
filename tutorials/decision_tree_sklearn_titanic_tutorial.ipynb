{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decision_tree_sklearn_titanic_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyND/31UjrpBEcmxATI8A+/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewpecsok/4482_fall_2022/blob/main/tutorials/decision_tree_sklearn_titanic_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5uVUd5CN-40"
      },
      "source": [
        "\n",
        "\n",
        "decision tree titanic tutorial\n",
        "\n",
        "Dr. Olivia Sheng\n",
        "September 16, 2016\n",
        "\n",
        "Converted to python by Steven Wang and Matthew Pecsok 5/2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irZn-wtVPQBX"
      },
      "source": [
        "## table of contents\n",
        "\n",
        "1.   Data Description\n",
        "2.   Set up, data import and inspections\n",
        "3.   Build decision trees\n",
        "4.   Post-model-building data exploration\n",
        "5.   Generate performance metrics\n",
        "6.   Simple hold-out evaluation\n",
        "7.   Tree pruning/unpruning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUwo-VbLOHPj"
      },
      "source": [
        "# 1 Data Description\n",
        "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people such as women, children, and the upper-class were more likely to survive than others.\n",
        "\n",
        "VARIABLE DESCRIPTIONS:\n",
        "\n",
        "PassengerID Unique passenger identifier Survived Survival (0 = No; 1 = Yes) Pclass Passenger Class(1 = 1st; 2 = 2nd; 3 = 3rd) (Pclass is a proxy for socio-economic status (SES) 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower) Name Name Sex Sex Age Age (Age is in Years; Fractional if Age less than One (1) If the Age is Estimated, it is in the form xx.5) Sibsp Number of Siblings/Spouses Aboard Parch Number of Parents/Children Aboard Ticket Ticket Number Fare Passenger Fare Cabin Cabin Embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE-c91reV6L5"
      },
      "source": [
        "# 2 Set up, data import and inspections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr12XFjDQYEq"
      },
      "source": [
        "## load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLQD3Ez_16UD"
      },
      "source": [
        "## Load packages \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ33SnW9QZz2"
      },
      "source": [
        "## import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVYjSjc3P3bf"
      },
      "source": [
        "# read_csv has some defaults, we can just take the defaults here, but be aware they exist. \n",
        "titanic_raw = pd.read_csv(\"https://raw.githubusercontent.com/matthewpecsok/4482_fall_2022/main/data/titanic_cleaned.csv\")\n",
        "titanic = titanic_raw.copy()\n",
        "\n",
        "# raw is the original unedited version of our data which can be useful for inspecting changes we've made \n",
        "# compared to the original unedited data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lavHznJRuvF"
      },
      "source": [
        "## get summary statistics of dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2AGzKsIQbyZ"
      },
      "source": [
        "titanic.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnpxYpjgQhj9"
      },
      "source": [
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Gp_my_QjRj"
      },
      "source": [
        "titanic.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2a13bPuRWsZ"
      },
      "source": [
        "# count null values (extremely important to identify nulls)\n",
        "\n",
        "titanic.isnull().sum()\n",
        "\n",
        "# no nulls, that's good news and almost never what happens in the real world."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs-vNe9isg1a"
      },
      "source": [
        "titanic.Survived.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvq6s-5rs6At"
      },
      "source": [
        "round(titanic.Survived.value_counts() / len(titanic),2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abggZMSYRAk0"
      },
      "source": [
        "## transform character/string to categorical (factor in R)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDM_EbWkRFoo"
      },
      "source": [
        "# astype is function in pandas that allows one to convert from one type of data to another ie string to int, or in this \n",
        "# case string to categorical\n",
        "# https://pandas.pydata.org/docs/reference/api/pandas.Categorical.html\n",
        "\n",
        "titanic = titanic.astype({'Survived': 'category',\n",
        "                                          'Sex': 'category',\n",
        "                                          'Pclass': 'category',\n",
        "                                          'Cabin': 'category',\n",
        "                                          'Embarked': 'category'})\n",
        "titanic.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIhfilbfSRtH"
      },
      "source": [
        "## dummy encode the data\n",
        "\n",
        "these models cannot handle string/words. they must be converted to numeric values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM0zfuf6Se5x"
      },
      "source": [
        "# extract the target column of survived. target aka y\n",
        "# while R is happy to have the target in the dataframe with the X predictors sklearn prefers them separate\n",
        "y_target = titanic.pop('Survived')\n",
        "\n",
        "# use pandas get_dummies to one-hot-encode categorical values\n",
        "# we would expect only numeric values left in our dataframe\n",
        "# rename this df as encoded so we understand it's the encoded version\n",
        "# of the original\n",
        "titanic_encoded_X = pd.get_dummies(titanic)\n",
        "\n",
        "titanic_encoded_X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqSodLE1S-0i"
      },
      "source": [
        "# lucky for us the binary target values are already numeric ie 0,1 instead of \"yes\",\"no\" \"true\",\"false\" etc\n",
        "# this saves us a step of having to encode the series. \n",
        "y_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7fWYyDDWYqm"
      },
      "source": [
        "# 3 build decision trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usHG_gNYUwW_"
      },
      "source": [
        "# random state\n",
        "# set random state for all models for reproducbility\n",
        "# if this is NOT set then you will see variations each time you run the model\n",
        "# for this reason reproducibility is desirable in homeworks\n",
        "random_state = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWNBy7K3TxMx"
      },
      "source": [
        "# what is tree?\n",
        "tree\n",
        "\n",
        "# an instance of a sklearn tree classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFNBXeHAUrAs"
      },
      "source": [
        "tree_model_1 = tree.DecisionTreeClassifier(random_state=random_state,max_leaf_nodes=11)\n",
        "tree_model_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGQ8oJ4hhHZF"
      },
      "source": [
        "## model 1 (all data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjWSFEweWSRZ"
      },
      "source": [
        "### fit/train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdLm9JLSYAYX"
      },
      "source": [
        "# model 1 is a model trained on all the data. subsequent models will be variations of this model and should be compared to understand how these changes impact the model. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJk3cgFWVNVA"
      },
      "source": [
        "# note, there is a lot going on behind the scenes here fitting is a complex process\n",
        "# the first argument is a dataset of the predictors. the second is a series of the target or y variable. \n",
        "tree_model_1 = tree_model_1.fit(titanic_encoded_X,y_target) # this trains the model on the x and y data \n",
        "\n",
        "# check to see if the model is fited\n",
        "sklearn.utils.validation.check_is_fitted(tree_model_1) # only get output if model is not fitted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRX7S2DVWPe1"
      },
      "source": [
        "### see a textual view of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19zRYzXfWdfq"
      },
      "source": [
        "### plot the tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6pjsPCXWhlH"
      },
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "_ = tree.plot_tree(tree_model_1,\n",
        "                   feature_names=titanic_encoded_X.columns.to_list(), # make sure the feature names are in output\n",
        "                   filled=True) # filled true color codes by the class. shading indicates proportion or quality of split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euAuajRFhKD4"
      },
      "source": [
        "## model 2 (all data but with cabin removed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtD-5hNLdqMQ"
      },
      "source": [
        "# demonstrating how to drop all columns starting with \"Cabin\"\n",
        "titanic_encoded_X.drop(titanic_encoded_X.columns[titanic_encoded_X.columns.str.startswith('Cabin')], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQQ8RTPnhT3k"
      },
      "source": [
        "# create a new model 2\n",
        "tree_model_2 = tree.DecisionTreeClassifier(random_state=random_state,max_leaf_nodes=11)\n",
        "tree_model_2\n",
        "\n",
        "# intentionally drop the cabin column. pay attention to the decision to do this \n",
        "# if we drop a column should it increase or decrease model performance? Can you know this ahead of time?\n",
        "titanic_encoded_X_no_cabin = titanic_encoded_X.drop(titanic_encoded_X.columns[titanic_encoded_X.columns.str.startswith('Cabin')], axis=1, inplace=False)\n",
        "\n",
        "\n",
        "# note, there is a lot going on behind the scenes here fitting is a complex process\n",
        "tree_model_2 = tree_model_2.fit(titanic_encoded_X_no_cabin,y_target) # this trains the model on the x and y data \n",
        "\n",
        "# check to see if the model is fitted\n",
        "sklearn.utils.validation.check_is_fitted(tree_model_2) # only get output if model is not fitted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltzrR25iWpuZ"
      },
      "source": [
        "### plot the tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c-a4KzAhStY"
      },
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "_ = tree.plot_tree(tree_model_2,\n",
        "                   feature_names=titanic_encoded_X.columns.to_list(), # make sure the feature names are in output\n",
        "                   filled=True) # filled true color codes by the class. shading indicates proportion or quality of split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r27l1opOg87C"
      },
      "source": [
        "# 4 Post-model-building data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wSo0g9Hhvec"
      },
      "source": [
        "# generate metrics for male and female passengers. in this notebook we will demonstrate doing what was done in R,\n",
        "# but in this case we will use a function to simplify the code\n",
        "# often when doing the same thing 2 or more times a function can reduce redundant code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVdSixzYifpZ"
      },
      "source": [
        "titanic[titanic['Sex']=='male'] # demonstration of how to filter a dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPoA3So-h_Ok"
      },
      "source": [
        "def metrics_by_gender(gender,df):\n",
        "  # filter df by gender\n",
        "  display(\"Dataframe subset of: \"+gender)\n",
        "\n",
        "  df = df[df['Sex']==gender]\n",
        "  \n",
        "  print(gender+\": shape\")\n",
        "  display(df.shape)\n",
        "\n",
        "  print(gender+\": describe\")\n",
        "  display(df.describe())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFHMjEFAiTbc"
      },
      "source": [
        "# demonstration of a very simple function that just subsets the dataframe and prints the new shape\n",
        "for gender in ['male','female']:\n",
        "  df = titanic[titanic['Sex']==gender]\n",
        "  print(gender)\n",
        "  print(df.shape)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw8PMvBQmbUW"
      },
      "source": [
        "# demonstration of a very simple function that just subsets the dataframe and prints the new shape\n",
        "for gender in ['male','female']:\n",
        "  df = titanic[titanic['Sex']==gender]\n",
        "  print(gender)\n",
        "  print(df.describe())\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5r1gIxSmsKt"
      },
      "source": [
        "# demonstration of a very simple function that just subsets the dataframe and prints the new shape\n",
        "for gender in ['male','female']:\n",
        "  df = titanic_raw[titanic_raw['Sex']==gender]\n",
        "  print(gender)\n",
        "  #print(df.groupby('Survived').value_counts())\n",
        "  print(df.groupby(['Survived','Pclass'])[['Pclass']].agg(['count']))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbeiPlAan-oz"
      },
      "source": [
        "for gender in ['male','female']:\n",
        "  df = titanic_raw[titanic_raw['Sex']==gender]\n",
        "  print(gender)\n",
        "  #print(df.groupby('Survived').value_counts())\n",
        "  print(df.groupby(['Survived','Embarked'])[['Embarked']].agg(['count']))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfQKggwfoRgz"
      },
      "source": [
        "# demonstrating a nested for loop\n",
        "# be careful of going much deeper than this in a loop \n",
        "# the code becomes very difficult to read\n",
        "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)   # ignore some ugly warnings because of code that is being deprecated\n",
        "\n",
        "for numeric_var in ['Age','Fare','Parch','SibSp']:\n",
        "  for gender in ['male','female'] :\n",
        "    df = titanic_raw[titanic_raw['Sex']==gender]\n",
        "    df.boxplot(column=[numeric_var],by=['Survived']) # R boxplot(Age~Survived, data = titanic)\n",
        "    plt.title( 'Boxplot of %s by Survived and Sex=%s' % (numeric_var,gender) )\n",
        "    plt.suptitle('')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFhTopLWqwK4"
      },
      "source": [
        "# 5 Generate performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7B7QFG3rFWU"
      },
      "source": [
        "# predict() applies a model (1st argument) to a testing data set (2nd argument).\n",
        "# Let's apply it to the whole data set that was used to train the model \n",
        "# to see the model's performance metrics in training data (i.e., not holdout evaluation)\n",
        "# Take a look at the structure and summary of predicted_Survived_w1 to understand the output of predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69OrJ8Xnbid-"
      },
      "source": [
        "# create a confusion matrix comparing y_true and y_predicted\n",
        "model_1_pred = tree_model_1.predict(titanic_encoded_X)\n",
        "\n",
        "print(model_1_pred)\n",
        "print(model_1_pred.shape)\n",
        "# pay attention to the predictions. how does the model choose 0 or 1 for the predictions? What is going on under the hood here? \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "varso_jLZXN5"
      },
      "source": [
        "predicted_probs = tree_model_1.predict_proba(titanic_encoded_X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NAc-A2QamjI"
      },
      "source": [
        "pd.DataFrame(data={'predicted_class':model_1_pred,'predicted_probability':predicted_probs[:,0],'real_class':y_target}) \n",
        "# so what's the relationship between the class and the probability?\n",
        "# nothing more than if prob >.5 then 0 else 1\n",
        "# can you see how we might begin to quantify how wrong a given prediction is from the truth?\n",
        "# when the model is uncertain we can expect the probability to be close to .5 in that case can \n",
        "# you see the model is getting the answer wrong? Is that surprising?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82SetOarrqE-"
      },
      "source": [
        "print(len(model_1_pred))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtRts6VFrr6g"
      },
      "source": [
        "model_1_cf = confusion_matrix(y_true=y_target,y_pred=model_1_pred)\n",
        "model_1_cf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp7lo8fgZarK"
      },
      "source": [
        "### model 1 & 2 performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL_7KzForync"
      },
      "source": [
        "model_2_pred = tree_model_2.predict(titanic_encoded_X_no_cabin)\n",
        "\n",
        "print(model_2_pred)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Rrbs52r56T"
      },
      "source": [
        "print(len(model_2_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RobtTvfqr56U"
      },
      "source": [
        "model_2_cf = confusion_matrix(y_true=y_target,y_pred=model_2_pred)\n",
        "model_2_cf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8aq_4GohCS2"
      },
      "source": [
        "### confusion matrix comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBKtqF3el-l"
      },
      "source": [
        "print(\"model1\")\n",
        "print(model_1_cf)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"model2\")\n",
        "print(model_2_cf)\n",
        "\n",
        "# does dropping cabin improve the model or make it worse?\n",
        "# notice that the model has decreased in performance for one class and increased in another. \n",
        "# is this model over or underfitted? more analysis needed to be certain.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GaLv9S_tHWe"
      },
      "source": [
        "### recall, precision f1 etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6q5c-o0sL3R"
      },
      "source": [
        "# performance of the tree_model_1\n",
        "# be sure to compare these metrics across the models\n",
        "# metrics themselves are more useful when comparing across models\n",
        "print(metrics.classification_report(y_target,tree_model_1.predict(titanic_encoded_X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf81go9jssYn"
      },
      "source": [
        "print(metrics.classification_report(y_target,tree_model_2.predict(titanic_encoded_X_no_cabin)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWc48_6at7aq"
      },
      "source": [
        "# 6 Simple hold-out evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-OJfy6huccm"
      },
      "source": [
        "# Examine the impacts of simple hold-out evaluation, the training set size, the feature selection and the pruning factor - CF\n",
        "\n",
        "# Only knowing the model's training performance is not sufficient. Let's try a simple hold-out evaluation. \n",
        "\n",
        "# Use train_test_split() in sklearn package to split titanic 50%-50% into a train set and a test set\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "# set random state to a value for train_test_split(). With the same value and input, "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH6IsxIylLrz"
      },
      "source": [
        "X_sample = [0,0,0,0,0,0,0,0,0,0,0,0,1,1]\n",
        "train_test_split(X_sample,test_size=.5,stratify=X_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtRJmGv4uEIJ"
      },
      "source": [
        "# split the dataset into two main groups\n",
        "# train will be used for training the model\n",
        "# test will be used for evaluation of the mode\n",
        "# both of these are simply subsets of the original dataset\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(titanic_encoded_X,\n",
        "                                                    y_target, \n",
        "                                                    test_size=.3, \n",
        "                                                    random_state=random_state,\n",
        "                                                    stratify=y_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLiGdFkzknxN"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKDAdelWkam_"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u1KcizQuu_z"
      },
      "source": [
        "X_train.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQX4kFVJuww8"
      },
      "source": [
        "X_test.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXzClqd-uzM6"
      },
      "source": [
        "print(y_train.value_counts())\n",
        "print(round(y_train.value_counts(normalize=True),2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoYyENoGu0H5"
      },
      "source": [
        "print(y_test.value_counts())\n",
        "print(round(y_test.value_counts(normalize=True),2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRxpBMT9wqip"
      },
      "source": [
        "## model 3 (simple hold out 70%/30% split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvEi7JEvc9xy"
      },
      "source": [
        "### fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6KEn9-lu5yW"
      },
      "source": [
        "model_3_simple_hold_out = tree.DecisionTreeClassifier(random_state=random_state,max_leaf_nodes=11)\n",
        "\n",
        "# fit the model to the training data\n",
        "model_3_simple_hold_out = model_3_simple_hold_out.fit(X_train, y_train)\n",
        "\n",
        "# show what the trained model looks like\n",
        "print(tree.export_text(model_3_simple_hold_out, feature_names=X_train.columns.to_list()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oKgIgG2wBu7"
      },
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "_ = tree.plot_tree(model_3_simple_hold_out,\n",
        "                   feature_names=X_train.columns.to_list(),\n",
        "                   filled=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgAdw2bxwuJC"
      },
      "source": [
        "### performance metrics of model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmuPH25MwUqC"
      },
      "source": [
        "model_3_pred = model_3_simple_hold_out.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_test,model_3_pred))\n",
        "print(metrics.confusion_matrix(y_test,model_3_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx32vSjWxUzD"
      },
      "source": [
        "## model 4 (simple hold out 70%/30% split and cabin removed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Iq3cJHxviy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udD1zN_SxySI"
      },
      "source": [
        "# another way to drop cabin columns\n",
        "# notice there are multiple ways to drop columns.\n",
        "\n",
        "# Drop Cabin\n",
        "X_train_no_cabin = X_train.drop(list(X_train.filter(regex = '^Cabin')), axis=1, inplace=False)\n",
        "X_test_no_cabin = X_test.drop(list(X_test.filter(regex = '^Cabin')), axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajPBMpFdc3L7"
      },
      "source": [
        "### fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9CeMQeVx7Pt"
      },
      "source": [
        "model_4 = tree.DecisionTreeClassifier(random_state=random_state,max_leaf_nodes=11)\n",
        "\n",
        "model_4 = model_4.fit(X_train_no_cabin, y_train)\n",
        "print(tree.export_text(model_4, feature_names=X_train_no_cabin.columns.to_list()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7NwpxKxZHuF"
      },
      "source": [
        "### plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBYRIVhvyak7"
      },
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "_ = tree.plot_tree(model_4,\n",
        "                   feature_names=X_train.columns.to_list(),\n",
        "                   filled=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i49UPI1zZKGB"
      },
      "source": [
        "### performance metrics of model 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZykO5dYPyfZv"
      },
      "source": [
        "# Test set performance metrics\n",
        "print(metrics.classification_report(y_test,model_4.predict(X_test_no_cabin)))\n",
        "print(metrics.confusion_matrix(y_test,model_4.predict(X_test_no_cabin)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWQKl7NQy65J"
      },
      "source": [
        "# 7 Regularization (tree model pruning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhCrVS6rzQFd"
      },
      "source": [
        "## model 5 (pruned tree on simple hold out 70%/30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQEXXvKzzhVJ"
      },
      "source": [
        "# check out alpha level on the default tree sklearn gives us.\n",
        "# notice it's set to 0!\n",
        "tree.DecisionTreeClassifier(random_state=random_state,max_leaf_nodes=11) #\n",
        "\n",
        "# notice we have set a new hyper parameter ccp_alpha\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eMcBcmz07GK"
      },
      "source": [
        "tree.DecisionTreeClassifier(random_state=random_state,max_leaf_nodes=11,ccp_alpha=.005) # notice we have set a new hyper parameter ccp_alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxg2EMNpyyZd"
      },
      "source": [
        "model_5 = tree.DecisionTreeClassifier(random_state=random_state,max_leaf_nodes=11,ccp_alpha=.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s9U6_SGdS3V"
      },
      "source": [
        "### fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l2rJVsFdT_g"
      },
      "source": [
        "model_5 = model_5.fit(X_train, y_train)\n",
        "print(tree.export_text(model_5, feature_names=X_train.columns.to_list()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecL94R6AZEy3"
      },
      "source": [
        "### plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1efvM2t31Myu"
      },
      "source": [
        "fig = plt.figure(figsize=(20,10))\n",
        "_ = tree.plot_tree(model_5,\n",
        "                   feature_names=X_train.columns.to_list(),\n",
        "                   filled=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYHS7WdjaR4H"
      },
      "source": [
        "### performance metrics of model 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67bqANAl1-0p"
      },
      "source": [
        "# Test set\n",
        "print(metrics.classification_report(y_test,model_5.predict(X_test)))\n",
        "print(metrics.confusion_matrix(y_test,model_5.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fTgjZiu2GPk"
      },
      "source": [
        "# Train set\n",
        "print(metrics.classification_report(y_train,model_5.predict(X_train)))\n",
        "print(metrics.confusion_matrix(y_train,model_5.predict(X_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M_XaVlPeF-4"
      },
      "source": [
        "# when viewing the performance metrics above which set did \"better\"? Why would the model perform better on the train set instead of the test set? What term do we use when this occurs?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajuq3VUZbHGP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}