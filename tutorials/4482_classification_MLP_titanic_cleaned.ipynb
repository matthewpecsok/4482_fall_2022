{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewpecsok/4482_fall_2022/blob/main/tutorials/4482_classification_MLP_titanic_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWVgdVutJP98"
      },
      "source": [
        "Welcome to the MLP classification notebook. In this notebook we will be exploring two new items. \n",
        "\n",
        "* The first will be learning how to use the MultiLayerPerceptron Algorithm. In the case that we start introducing hidden layers one would call this \"Deep Learning\" and \"Deep Neural Network\" which is an extremely powerful modeling technique. \n",
        "\n",
        "* The second concept which is extremely relevant for DNN is the selection of and tuning of hyperparameters. This selection can be computationally expensive and time consuming. For this we introduce sklearn's gridsearchcv to help us search/explore the parameter space without having to code this manually. \n",
        "\n",
        "* The notebook will begin by simply creating MLP models with various numbers of layers and a variety of neurons in each layer with the models becoming more computationally expensive and complex. Pay attention to the metrics to see if this complexity has actually improved our predictions. DNNs are notorious for overfitting data because they can become arbitrarily complex. \n",
        "\n",
        "* After you have grasped the primary concept of the DNN we will introduce other hyperparameters that are often tuned to improve the model, and finally we will introduce gridsearchcv to bring this code complexity back down to a reasonable effort. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKEFgC7Ycm_"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbDv78ea7uk-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix,\\\n",
        " recall_score, precision_score, f1_score, accuracy_score, make_scorer,\\\n",
        "  precision_recall_fscore_support\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqyRu9C4YfJy"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL9otp_39m7r"
      },
      "source": [
        "titanic_cleaned = pd.read_csv('https://raw.githubusercontent.com/matthewpecsok/4482_fall_2022/main/data/titanic_cleaned.csv').drop('Cabin', axis=1) # drop cabin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifk5nluWDuf7"
      },
      "source": [
        "titanic_cleaned.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKkWpTpV4jtk"
      },
      "source": [
        "titanic_cleaned['Pclass'] = titanic_cleaned.Pclass.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrKnruWR4kJ4"
      },
      "source": [
        "titanic_cleaned.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPWZ7XI44Dqw"
      },
      "source": [
        "y = titanic_cleaned.pop('Survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuEa_lDSW1-_"
      },
      "source": [
        "X = pd.get_dummies(titanic_cleaned)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQa9YZviloKQ"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9iyfH2CYgR8"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIdP_L-ctI8n"
      },
      "source": [
        "# Changing the number of hidden layers on the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsIzyTF9YhYj"
      },
      "source": [
        "### Model 1 (no hidden layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5YIii099yvB"
      },
      "source": [
        "model_1 = MLPClassifier(random_state=2021,hidden_layer_sizes=()).fit(X,y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqxcXGK3kLD_"
      },
      "source": [
        "model_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e223qTSskUe_"
      },
      "source": [
        "model_1.n_layers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7eAMdNnl7Yt"
      },
      "source": [
        "model_1.hidden_layer_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XakaR5Y0n1Mg"
      },
      "source": [
        "model_1.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm7R1ErRn3zQ"
      },
      "source": [
        "len(model_1.coefs_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_I61jLWoBX9"
      },
      "source": [
        "model_1.coefs_[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e15MbIq5pAFU"
      },
      "source": [
        "model_1.coefs_[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDviTtBk808N"
      },
      "source": [
        "model_1_cv_results = pd.DataFrame(cross_validate(model_1,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_1_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4nA2_FSYv_j"
      },
      "source": [
        "### Model 2 (1 hidden layer with 50 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K96ZGMf2CLbJ"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_2 = MLPClassifier(random_state=2021,hidden_layer_sizes=(50,)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_2.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_2.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy48EKnXBoIr"
      },
      "source": [
        "model_2_cv_results = pd.DataFrame(cross_validate(model_2,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_2_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUibNVruKyYZ"
      },
      "source": [
        "### Model 3 (2 hidden layers, the first has 15 neurons and the second has 10 neurons)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqt6FfL8H93J"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_3 = MLPClassifier(random_state=2021,hidden_layer_sizes=(15,10)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_3.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_3.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwrUqQn-IQ-t"
      },
      "source": [
        "model_3_cv_results = pd.DataFrame(cross_validate(model_3,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_3_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSo4c_syV9b"
      },
      "source": [
        "### Model 3 (3 hidden layers, the first has 50 neurons , the second has 25 neurons, the third has 10 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5C0UNi-PFpI"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_4 = MLPClassifier(random_state=2021,hidden_layer_sizes=(50,25,10)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_4.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_4.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZfbMW36PGTX"
      },
      "source": [
        "model_4_cv_results = pd.DataFrame(cross_validate(model_4,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_4_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eml2qocVydN8"
      },
      "source": [
        "### Model 5 (4 hidden layers, the first has 100 neurons , the second has 50 neurons, the third has 25 neurons and the fourth has 10 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rIiRM6hQEJr"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_5 = MLPClassifier(random_state=2021,hidden_layer_sizes=(100,50,25,10)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_5.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_5.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j9IP2eEQD9W"
      },
      "source": [
        "model_5_cv_results = pd.DataFrame(cross_validate(model_5,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_5_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-O7e8WsyruO"
      },
      "source": [
        "### Model 6 (5 hidden layers, the first has 100 neurons , the second has 50 neurons, the third has 25 neurons , the fourth has 25 neurons , the fifth has 10 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9QxFiMoTDWm"
      },
      "source": [
        "model_6_cv_results = pd.DataFrame(cross_validate(MLPClassifier(random_state=2021,hidden_layer_sizes=(100,50,25,25,10)),\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_6_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRToaqHdyzr-"
      },
      "source": [
        "### Model 7 (3 hidden layers each with 500 neurons)\n",
        "\n",
        "notice how much longer this model took to train compared to the others!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMOloEMwcdu"
      },
      "source": [
        "model_7_cv_results = pd.DataFrame(cross_validate(MLPClassifier(random_state=2021,hidden_layer_sizes=(500,500,500)),\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_7_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHuOl_DVvNQI"
      },
      "source": [
        "model_1_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfghrQu6vT_h"
      },
      "source": [
        "model_2_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9teCt2RvVtn"
      },
      "source": [
        "model_3_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSQQXq8tvVer"
      },
      "source": [
        "model_4_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbzOddXEvVEF"
      },
      "source": [
        "model_5_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSTAK9nYvUZC"
      },
      "source": [
        "model_6_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfxIu3qV2lMx"
      },
      "source": [
        "model_7_cv_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7H7O32mvqUA"
      },
      "source": [
        "Analyzing the results as shown above notice that the performance of the models is not always increasing even though the complexity is increasing. The increased complexity does seem to increase the fit time though which is expected. A more complex model will take longer to train. So there is a trade off between quality of the model and complexity of the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGWHzTfuwAG6"
      },
      "source": [
        "In addition, notice how much code we had to write just to get these results? And if you were starting to feel like the code is redundant for each section you are correct! Notice with a simple function how we can do exactly the same thing much easier as shown below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FynCPR_Yvppx"
      },
      "source": [
        "model_1_hidden_layers = ()\n",
        "model_2_hidden_layers = (50,)\n",
        "model_3_hidden_layers = (15,10)\n",
        "model_4_hidden_layers = (50,25,10)\n",
        "model_5_hidden_layers = (100,50,25,10)\n",
        "model_6_hidden_layers = (100,50,25,25,10)\n",
        "model_7_hidden_layers = (500,500,500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5miNVeucw8Wl"
      },
      "source": [
        "# create a function to train/evaluate the model using cross validation and return the\n",
        "# results as a dataframe\n",
        "def cv_mlp_models(hidden_layer_param):\n",
        "  return_df = pd.DataFrame(cross_validate(MLPClassifier(random_state=2021,hidden_layer_sizes=hidden_layer_param),\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "  return_df['hidden'] = str(hidden_layer_param)\n",
        "  return return_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQpRY5BR0b81"
      },
      "source": [
        "# now simply join all the result dataframes together\n",
        "def join_dfs(df,concat_df):\n",
        "  concat_df = concat_df.append(df)\n",
        "  return concat_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbQSZUCMzPR2"
      },
      "source": [
        "# make a list of the hidden layer tuples so we can interate over it with a for loop\n",
        "list_of_hidden_layers = [model_1_hidden_layers,model_2_hidden_layers,model_3_hidden_layers,model_4_hidden_layers,model_5_hidden_layers,model_6_hidden_layers,model_7_hidden_layers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Spa7dBfzarL"
      },
      "source": [
        "# create an empty dataframe with the correct column names, we need this so we have a dataframe that can collect all our results\n",
        "concat_df = pd.DataFrame(columns=['fit_time',\t'score_time'\t,'test_accuracy',\t'train_accuracy',\t'test_recall',\t'train_recall',\t'test_precision',\t'train_precision',\t'test_f1',\t'train_f1'])\n",
        "\n",
        "# now simply iterate over our list of hidden layers, run the cv function for each hidden layer setting, and append all the results\n",
        "for model_hidden_layer in list_of_hidden_layers:\n",
        "  result_df = cv_mlp_models(model_hidden_layer)\n",
        "  concat_df = join_dfs(result_df,concat_df)\n",
        "\n",
        "concat_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61yN_Un_3sW8"
      },
      "source": [
        "# Learning Rate Hyperparameter\n",
        "\n",
        "Before this we were simply looking at the number of hidden layers and the quantity of neurons in this hidden layers to improve our model. Another common tuning hyperparameter is learning rate. This is the rate at which the weights are adjusted and has two primary benefits. The first is that a learning weight can impact the models ability to learn more quickly or slowly and second that it can help the model stay out of local minima and hopefully find the globbal minumum when reducing loss as it is getting tuned.\n",
        "\n",
        "Let's do a quick exploration of this and its impact on training using a simple example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdQiXqEu4p4A"
      },
      "source": [
        "pd.DataFrame(cross_validate(MLPClassifier(random_state=2021,hidden_layer_sizes=(500,500,500),\n",
        "                                          learning_rate_init=0.001), # note that 0.001 is the DEFAULT learning rate\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Anz5M_4wxF"
      },
      "source": [
        "now we adjust the learning rate and make it smaller to see if we can improve the model's accuracy, precision, recall etc.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvYJY95k1DDC"
      },
      "source": [
        "pd.DataFrame(cross_validate(MLPClassifier(random_state=2021,hidden_layer_sizes=(500,500,500),\n",
        "                                          learning_rate_init=0.0001), \n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXFQ_g2y6Udq"
      },
      "source": [
        "it appears the model is almost as good as the original, and it took almost twice as long to train! while 18 seconds may not be too long to wait imagine this model takes 6 hours, then reducing the training time to 3 hours could be a significant advantage and if the accuracy is almost the same there's almost no disadvantage to doing so"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx1kNWjN6vdl"
      },
      "source": [
        "# GridSearchCV\n",
        "\n",
        "In addition to hidden layer size and depth, learning rate, there are also momentum and the maximum number of passes that could be tuned and MANY others! This gets overwhelming quite quickly and isn't efficient for us to try to test them all! Imagine writing the code to test the following\n",
        "\n",
        "* 5 possible hidden layer sizes\n",
        "* 6 possible learning rates\n",
        "* 4 possible momentums\n",
        "* 6 possible total numbers of passes\n",
        "\n",
        "That is 5 *6 * 4 * 6 = 720 possible combinations! thats way too many to try and write by hand.\n",
        "\n",
        "### Introducing GridSearch\n",
        "\n",
        "GridSearch can try all of those combinations for you and simplify your code\n",
        "\n",
        "note that I have chosen to use F1 as the primary metric for the grid search to use to evaluate the hyperparameter combinations. The grid search will return the best combination that maximizes the F1 score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVG64ZKC5Euh"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'learning_rate_init':[0.1,0.01,0.001],\n",
        "               'hidden_layer_sizes':[(50,),(50,50,50),(4,4,4)],\n",
        "              'activation':['identity', 'logistic', 'tanh', 'relu','adam']\n",
        "              }\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "clf = GridSearchCV(mlp, parameters,scoring='f1')\n",
        "clf.fit(X, y)\n",
        "\n",
        "clf.score(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBaNEttvNyam"
      },
      "source": [
        "# this is a complex dataframe that shows all of the various metrics you might want to look\n",
        "# into if you want to understand how the grid search worked.\n",
        "# a scenario might be: what if the grid search returns the \"best\" model but it takes 2 days to fit? (some DNNs take this long or longer to train)\n",
        "# and is only slightly better than another model which takes 10 minutes to train. you might not bother\n",
        "# picking the \"best\" model in that case\n",
        "\n",
        "grid_search_df = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "print(grid_search_df.shape) # we trained 30 models! is that what you would expect?\n",
        "\n",
        "grid_search_df.sort_values('mean_test_score',ascending=False).head() #only taking the top five rows as this is a large dataframe sort by the best f1 scores found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_odr0cJMLmr"
      },
      "source": [
        "after the gridsearch explores all the model combinations it selects the best model set of hyperparameters to be used. Once this model is trained it may result in an improvement over our previous efforts. Notice that I have not explored EVERY possible model we created previously and have instead opted to explore a variety of other hyperparameters to see if it's possible to achieve a better prediction than we achieved previously in the notebook. \n",
        "\n",
        "The point to take away from this is that\n",
        "1. There are an infinite number of hyperparameter combinations\n",
        "1. It's impossible to explore them all by hand\n",
        "1. For each combination a model must be trained\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs4GWJ3B8iw7"
      },
      "source": [
        "# note the hyperpameters that the gridsearch discovered achieve the best results\n",
        "clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfr1x2Da8yS9"
      },
      "source": [
        "pd.DataFrame(cross_validate(clf, \n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyYW-h3_FQ9E"
      },
      "source": [
        "compare this test_f1 to the test_f1 results we had from the other models. Have we improved the model's f1 score on the test set? And, was it easier than all the code we wrote before?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSeGAAV_vIlO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}